---
title: Understanding Alignment
pubDate: 2025-07-15
description: Is alignment tractable?
layout: blog.njk
---

Given the recently publicized efforts towards the creation of Artificial Superintelligence and the associated problem of "superalignment" (the alignment of superintelligent systems) I was curious about whether this problem was tractable on a ==philosophical==, ==technical==, and ==sociopolitical== level.

<br>

**Philosophically:** Can we define "human values" in a way that is precise, coherent, and acceptable enough to guide a superintelligent system?

**Technically:** Even if we could define human values, is it technically possible to make an AI understand and obey them robustly?

**Sociopolitically:** Even if we had a philosophical consensus and technical solution, could we realistically coordinate global actors to implement it?

<br>

I don't have much expertise on the former and I don't have much hope for the latter.

<br>

I thought I'd run the question on technical tractability by Gemini Deep Research, and [this](https://docs.google.com/document/d/1gRrMDbVXGVVyDYZR91tSaHE7pe9Ueaw6kIfV-MPTHd4/edit?usp=sharing) is what it produced.

I found its description of the paradoxical nature of current approaches to superalignment to be captivating and wanted to share.

I was also a bit surprised by how convinced I was after reading this article. These tools are getting insanely good! I also just read the article it produced today; perhaps I need more time to digest.

<br>

I'm still personally curious about the philosophical nature of superalignment. These are some points that ChatGPT and I thought may be important:

### Key concepts:
- Value alignment vs. value learning
- Moral realism vs. anti-realism
- Value pluralism (Is there even one set of values to align with?)
- ==Coherent Extrapolated Volition (Yudkowsky)== -- I especially recommend this reading

### Main difficulties:
- Human values are often vague, conflicting, and context-dependent.
- There is no consensus on what "doing the right thing" means, even for humans.
- Cultural and moral diversity complicates any universal alignment effort.

### Debates:
- Can we formalize values at all? (philosophy of language, ethics)
- Should AI systems align to individual preferences, aggregate preferences, or an idealized extrapolation?]

> _More to come_